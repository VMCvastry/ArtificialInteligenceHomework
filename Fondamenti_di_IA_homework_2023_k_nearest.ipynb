{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TspH1wJmAkdk"
   },
   "source": [
    "### For the homeworks we are going to use the \"[Online News Popularity Data Set](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity#)\"\n",
    "\n",
    "The dataset can be used both for regression and classification tasks.\n",
    "\n",
    "#### Source:\n",
    "\n",
    "Kelwin Fernandes INESC TEC, Porto, Portugal/Universidade do Porto, Portugal.\n",
    "Pedro Vinagre ALGORITMI Research Centre, Universidade do Minho, Portugal\n",
    "Paulo Cortez ALGORITMI Research Centre, Universidade do Minho, Portugal\n",
    "Pedro Sernadela Universidade de Aveiro\n",
    "\n",
    "#### Data Set Information:\n",
    "\n",
    "* The articles were published by Mashable (www.mashable.com) and their content as the rights to reproduce it belongs to them. Hence, this dataset does not share the original content but some statistics associated with it. The original content be publicly accessed and retrieved using the provided urls.\n",
    "* Acquisition date: January 8, 2015\n",
    "* The estimated relative performance values were estimated by the authors using a Random Forest classifier and a rolling windows as assessment method. See their article for more details on how the relative performance values were set.\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "Number of Attributes: 61 (58 predictive attributes, 2 non-predictive, 1 goal field)\n",
    "\n",
    "Attribute Information:\n",
    "0. url: URL of the article (non-predictive)\n",
    "1. timedelta: Days between the article publication and the dataset acquisition (non-predictive)\n",
    "2. n_tokens_title: Number of words in the title\n",
    "3. n_tokens_content: Number of words in the content\n",
    "4. n_unique_tokens: Rate of unique words in the content\n",
    "5. n_non_stop_words: Rate of non-stop words in the content\n",
    "6. n_non_stop_unique_tokens: Rate of unique non-stop words in the content\n",
    "7. num_hrefs: Number of links\n",
    "8. num_self_hrefs: Number of links to other articles published by Mashable\n",
    "9. num_imgs: Number of images\n",
    "10. num_videos: Number of videos\n",
    "11. average_token_length: Average length of the words in the content\n",
    "12. num_keywords: Number of keywords in the metadata\n",
    "13. data_channel_is_lifestyle: Is data channel 'Lifestyle'?\n",
    "14. data_channel_is_entertainment: Is data channel 'Entertainment'?\n",
    "15. data_channel_is_bus: Is data channel 'Business'?\n",
    "16. data_channel_is_socmed: Is data channel 'Social Media'?\n",
    "17. data_channel_is_tech: Is data channel 'Tech'?\n",
    "18. data_channel_is_world: Is data channel 'World'?\n",
    "19. kw_min_min: Worst keyword (min. shares)\n",
    "20. kw_max_min: Worst keyword (max. shares)\n",
    "21. kw_avg_min: Worst keyword (avg. shares)\n",
    "22. kw_min_max: Best keyword (min. shares)\n",
    "23. kw_max_max: Best keyword (max. shares)\n",
    "24. kw_avg_max: Best keyword (avg. shares)\n",
    "25. kw_min_avg: Avg. keyword (min. shares)\n",
    "26. kw_max_avg: Avg. keyword (max. shares)\n",
    "27. kw_avg_avg: Avg. keyword (avg. shares)\n",
    "28. self_reference_min_shares: Min. shares of referenced articles in Mashable\n",
    "29. self_reference_max_shares: Max. shares of referenced articles in Mashable\n",
    "30. self_reference_avg_sharess: Avg. shares of referenced articles in Mashable\n",
    "31. weekday_is_monday: Was the article published on a Monday?\n",
    "32. weekday_is_tuesday: Was the article published on a Tuesday?\n",
    "33. weekday_is_wednesday: Was the article published on a Wednesday?\n",
    "34. weekday_is_thursday: Was the article published on a Thursday?\n",
    "35. weekday_is_friday: Was the article published on a Friday?\n",
    "36. weekday_is_saturday: Was the article published on a Saturday?\n",
    "37. weekday_is_sunday: Was the article published on a Sunday?\n",
    "38. is_weekend: Was the article published on the weekend?\n",
    "39. LDA_00: Closeness to LDA topic 0\n",
    "40. LDA_01: Closeness to LDA topic 1\n",
    "41. LDA_02: Closeness to LDA topic 2\n",
    "42. LDA_03: Closeness to LDA topic 3\n",
    "43. LDA_04: Closeness to LDA topic 4\n",
    "44. global_subjectivity: Text subjectivity\n",
    "45. global_sentiment_polarity: Text sentiment polarity\n",
    "46. global_rate_positive_words: Rate of positive words in the content\n",
    "47. global_rate_negative_words: Rate of negative words in the content\n",
    "48. rate_positive_words: Rate of positive words among non-neutral tokens\n",
    "49. rate_negative_words: Rate of negative words among non-neutral tokens\n",
    "50. avg_positive_polarity: Avg. polarity of positive words\n",
    "51. min_positive_polarity: Min. polarity of positive words\n",
    "52. max_positive_polarity: Max. polarity of positive words\n",
    "53. avg_negative_polarity: Avg. polarity of negative words\n",
    "54. min_negative_polarity: Min. polarity of negative words\n",
    "55. max_negative_polarity: Max. polarity of negative words\n",
    "56. title_subjectivity: Title subjectivity\n",
    "57. title_sentiment_polarity: Title polarity\n",
    "58. abs_title_subjectivity: Absolute subjectivity level\n",
    "59. abs_title_sentiment_polarity: Absolute polarity level\n",
    "60. shares: Number of shares (target)\n",
    "\n",
    "\n",
    "The first two columns (url and time_delta) are non-predictive and should be ignored\n",
    "\n",
    "The last column **shares** contains the value to predict.\n",
    "\n",
    "### Regression\n",
    "In the case of regression we want to predict the value of the share column.\n",
    "\n",
    "### Classification\n",
    "In the case of classification we want to predict one of two classes:\n",
    "\n",
    "* *low* -- shares < 1,400\n",
    "* *high* -- shares >= 1,400\n",
    "\n",
    "### Metrics\n",
    "\n",
    "#### Regression\n",
    "To evaluate how good we are doing on the **regression** task we will use the Root Mean Squared Error (RMSE). RMSE is given by\n",
    "\n",
    "$$\n",
    "\\sqrt{\\frac{1}{n}\\sum\\limits_{i=1}^{n}{\\Big(d_i -f_i\\Big)^2}}\n",
    "$$\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "* $n$ is the number of test samples\n",
    "* $d_i$ is the ground truth value of the i-th sample\n",
    "* $f_i$ is the predicted value of the i-th sample\n",
    "\n",
    "\n",
    "#### Classification\n",
    "To evaluate how good we are doing on the **classification** task we will use the accuracy metrics. Accuracy is given by\n",
    "\n",
    "$$\n",
    "\\frac{TP+TN}{TP+TN+FP+FN}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* TP is the number of *correctly* classified positive samples\n",
    "* TN is the number of *correctly* classified negative samples\n",
    "* FP is the number of *incorrectly* classified positive samples\n",
    "* FN is the number of *incorrectly* classified negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oesd6_bYijRo",
    "outputId": "a840832a-3520-47e8-9939-6224b0bb241b",
    "ExecuteTime": {
     "start_time": "2023-04-03T23:37:32.758512Z",
     "end_time": "2023-04-03T23:37:33.429794Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmad6QdZ_nFR",
    "outputId": "bfbf18fd-0edd-4424-b696-f48ccff3a4a6",
    "ExecuteTime": {
     "start_time": "2023-04-03T23:37:33.430753Z",
     "end_time": "2023-04-03T23:37:33.433255Z"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https: // archive.ics.uci.edu / ml / machine-learning-databases / 00332 / OnlineNewsPopularity.zip\n",
    "# !unzip OnlineNewsPopularity.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Format properly the names of the columns and remove the first two columns"
   ],
   "metadata": {
    "id": "yXCX_LpFedtj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "#VARIABLES\n",
    "BINARY_LABEL = True\n",
    "NORMALIZE = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T00:02:22.792011Z",
     "end_time": "2023-04-04T00:02:22.839088Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1mxntjhmAH0D",
    "ExecuteTime": {
     "start_time": "2023-04-03T23:38:03.230768Z",
     "end_time": "2023-04-03T23:38:03.473182Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('OnlineNewsPopularity/OnlineNewsPopularity.csv')\n",
    "df = df.rename(columns=lambda x: x.strip())\n",
    "df = df.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's plot some of the columns"
   ],
   "metadata": {
    "id": "mu_rxzq0f2gV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VbFlnYRjAXlk",
    "outputId": "e9048aa7-7f2f-4e22-b550-92237f8d5512",
    "ExecuteTime": {
     "start_time": "2023-04-03T23:38:08.121503Z",
     "end_time": "2023-04-03T23:38:08.421473Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "columns_to_plot = [\n",
    "    'n_tokens_title',\n",
    "    'num_videos',\n",
    "    'num_imgs',\n",
    "    'num_keywords',\n",
    "    'data_channel_is_world',\n",
    "    'rate_negative_words',\n",
    "    'self_reference_avg_sharess',\n",
    "]\n",
    "#\n",
    "# fig, ax = plt.subplots(len(columns_to_plot), 1, figsize=(20, 20))\n",
    "#\n",
    "# for i, column in enumerate(columns_to_plot, 0):\n",
    "#     ax[i].hist(df[column])\n",
    "#     ax[i].title.set_text(column)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens_title                       10.398749\n",
      "n_tokens_content                    546.514731\n",
      "n_unique_tokens                       0.548216\n",
      "n_non_stop_words                      0.996469\n",
      "n_non_stop_unique_tokens              0.689175\n",
      "num_hrefs                            10.883690\n",
      "num_self_hrefs                        3.293638\n",
      "num_imgs                              4.544143\n",
      "num_videos                            1.249874\n",
      "average_token_length                  4.548239\n",
      "num_keywords                          7.223767\n",
      "data_channel_is_lifestyle             0.052946\n",
      "data_channel_is_entertainment         0.178009\n",
      "data_channel_is_bus                   0.157855\n",
      "data_channel_is_socmed                0.058597\n",
      "data_channel_is_tech                  0.185299\n",
      "data_channel_is_world                 0.212567\n",
      "kw_min_min                           26.106801\n",
      "kw_max_min                         1153.951682\n",
      "kw_avg_min                          312.366967\n",
      "kw_min_max                        13612.354102\n",
      "kw_max_max                       752324.066694\n",
      "kw_avg_max                       259281.938083\n",
      "kw_min_avg                         1117.146610\n",
      "kw_max_avg                         5657.211151\n",
      "kw_avg_avg                         3135.858639\n",
      "self_reference_min_shares          3998.755396\n",
      "self_reference_max_shares         10329.212662\n",
      "self_reference_avg_sharess         6401.697580\n",
      "weekday_is_monday                     0.168020\n",
      "weekday_is_tuesday                    0.186409\n",
      "weekday_is_wednesday                  0.187544\n",
      "weekday_is_thursday                   0.183306\n",
      "weekday_is_friday                     0.143805\n",
      "weekday_is_saturday                   0.061876\n",
      "weekday_is_sunday                     0.069039\n",
      "is_weekend                            0.130915\n",
      "LDA_00                                0.184599\n",
      "LDA_01                                0.141256\n",
      "LDA_02                                0.216321\n",
      "LDA_03                                0.223770\n",
      "LDA_04                                0.234029\n",
      "global_subjectivity                   0.443370\n",
      "global_sentiment_polarity             0.119309\n",
      "global_rate_positive_words            0.039625\n",
      "global_rate_negative_words            0.016612\n",
      "rate_positive_words                   0.682150\n",
      "rate_negative_words                   0.287934\n",
      "avg_positive_polarity                 0.353825\n",
      "min_positive_polarity                 0.095446\n",
      "max_positive_polarity                 0.756728\n",
      "avg_negative_polarity                -0.259524\n",
      "min_negative_polarity                -0.521944\n",
      "max_negative_polarity                -0.107500\n",
      "title_subjectivity                    0.282353\n",
      "title_sentiment_polarity              0.071425\n",
      "abs_title_subjectivity                0.341843\n",
      "abs_title_sentiment_polarity          0.156064\n",
      "shares                             3395.380184\n",
      "dtype: float64\n",
      "n_tokens_title                       10.000000\n",
      "n_tokens_content                    409.000000\n",
      "n_unique_tokens                       0.539226\n",
      "n_non_stop_words                      1.000000\n",
      "n_non_stop_unique_tokens              0.690476\n",
      "num_hrefs                             8.000000\n",
      "num_self_hrefs                        3.000000\n",
      "num_imgs                              1.000000\n",
      "num_videos                            0.000000\n",
      "average_token_length                  4.664082\n",
      "num_keywords                          7.000000\n",
      "data_channel_is_lifestyle             0.000000\n",
      "data_channel_is_entertainment         0.000000\n",
      "data_channel_is_bus                   0.000000\n",
      "data_channel_is_socmed                0.000000\n",
      "data_channel_is_tech                  0.000000\n",
      "data_channel_is_world                 0.000000\n",
      "kw_min_min                           -1.000000\n",
      "kw_max_min                          660.000000\n",
      "kw_avg_min                          235.500000\n",
      "kw_min_max                         1400.000000\n",
      "kw_max_max                       843300.000000\n",
      "kw_avg_max                       244572.222223\n",
      "kw_min_avg                         1023.635611\n",
      "kw_max_avg                         4355.688836\n",
      "kw_avg_avg                         2870.074878\n",
      "self_reference_min_shares          1200.000000\n",
      "self_reference_max_shares          2800.000000\n",
      "self_reference_avg_sharess         2200.000000\n",
      "weekday_is_monday                     0.000000\n",
      "weekday_is_tuesday                    0.000000\n",
      "weekday_is_wednesday                  0.000000\n",
      "weekday_is_thursday                   0.000000\n",
      "weekday_is_friday                     0.000000\n",
      "weekday_is_saturday                   0.000000\n",
      "weekday_is_sunday                     0.000000\n",
      "is_weekend                            0.000000\n",
      "LDA_00                                0.033387\n",
      "LDA_01                                0.033345\n",
      "LDA_02                                0.040004\n",
      "LDA_03                                0.040001\n",
      "LDA_04                                0.040727\n",
      "global_subjectivity                   0.453457\n",
      "global_sentiment_polarity             0.119117\n",
      "global_rate_positive_words            0.039023\n",
      "global_rate_negative_words            0.015337\n",
      "rate_positive_words                   0.710526\n",
      "rate_negative_words                   0.280000\n",
      "avg_positive_polarity                 0.358755\n",
      "min_positive_polarity                 0.100000\n",
      "max_positive_polarity                 0.800000\n",
      "avg_negative_polarity                -0.253333\n",
      "min_negative_polarity                -0.500000\n",
      "max_negative_polarity                -0.100000\n",
      "title_subjectivity                    0.150000\n",
      "title_sentiment_polarity              0.000000\n",
      "abs_title_subjectivity                0.500000\n",
      "abs_title_sentiment_polarity          0.000000\n",
      "shares                             1400.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#calculate median for each column\n",
    "median = df.median(axis=0)\n",
    "avg = df.mean(axis=0)\n",
    "print(avg)\n",
    "print(median)\n",
    "# compute the median of each attribute\n",
    "medians = df.median()\n",
    "\n",
    "# discretize each attribute to 0 or 1 based on the median\n",
    "# for column in df.columns:\n",
    "#     df[column] = (df[column] >= medians[column]).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T23:38:10.270961Z",
     "end_time": "2023-04-03T23:38:10.335280Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data = np.array(df)\n",
    "if NORMALIZE:\n",
    "    # normalize the data\n",
    "    data = (data - data.mean(axis=0)) / data.std(axis=0)\n",
    "x = data[:, :-1]\n",
    "# converting the last column to boolean\n",
    "if BINARY_LABEL:\n",
    "    if not NORMALIZE:\n",
    "        y = np.array([elem >= 1400 for elem in data[:, -1]])\n",
    "    else:\n",
    "        y = np.array([e >= 0 for e in data[:, -1]])  #TODO check\n",
    "else:\n",
    "    y = np.array(data[:, -1])\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "dLIoAQQY-ql_",
    "outputId": "bf5d14ac-b0f6-410e-98cd-d69cea64e8ea",
    "ExecuteTime": {
     "start_time": "2023-04-04T00:02:25.828727Z",
     "end_time": "2023-04-04T00:02:25.881241Z"
    }
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def analyze_pred(pred, truth):\n",
    "    # Print the mean squared error and R-squared score\n",
    "    print('Mean Squared Error:', mean_squared_error(truth, pred))\n",
    "    print('R-squared Score:', r2_score(test_y, pred))\n",
    "    print(np.mean(pred))\n",
    "    print(np.mean(truth))\n",
    "    bin_pred = pred >= 0\n",
    "    bin_truth = truth >= 0\n",
    "    print('Accuracy:', accuracy_score(bin_truth, bin_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T23:39:29.362005Z",
     "end_time": "2023-04-03T23:39:29.381916Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def analyze_pred_bin(pred, truth):\n",
    "    # Print the mean squared error and R-squared score\n",
    "    print('Binary cross entropy:', log_loss(truth, pred))\n",
    "    print(np.mean(pred))\n",
    "    print(np.mean(truth))\n",
    "    # bin_pred = pred >= 0\n",
    "    # bin_truth = truth >= 0\n",
    "    print('Accuracy:', accuracy_score(truth, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T23:42:12.401791Z",
     "end_time": "2023-04-03T23:42:12.446916Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def test_model(model, train_x, train_y, test_x, test_y,classification=False):\n",
    "    time_start = time.time()\n",
    "    model.fit(train_x, train_y)\n",
    "    print(\"Time taken to train the model: \", time.time() - time_start)\n",
    "    pred = model.predict(test_x)\n",
    "    if classification:\n",
    "        analyze_pred_bin(pred, test_y)\n",
    "    else:\n",
    "        analyze_pred(pred, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T23:42:32.625693Z",
     "end_time": "2023-04-03T23:42:32.667510Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train the model:  0.001749277114868164\n",
      "Mean Squared Error: 0.6476286041930105\n",
      "R-squared Score: -0.24005196319638644\n",
      "-0.029363834499985204\n",
      "-0.01342905790679993\n",
      "Accuracy: 0.7037457434733257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "\n",
    "\n",
    "# Print the regression coefficients and intercept\n",
    "# print('Coefficients:', regressor.coef_)\n",
    "# print('Intercept:', regressor.intercept_)\n",
    "test_model(regressor, train_x, train_y, test_x, test_y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T23:42:35.639175Z",
     "end_time": "2023-04-03T23:42:36.134791Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train the model:  0.002966642379760742\n",
      "Binary cross entropy: 8.068796161644968\n",
      "0.07592382393744482\n",
      "0.20267372934796318\n",
      "Accuracy: 0.7761382267625173\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "test_model(classifier, train_x, train_y, test_x, test_y,classification=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T23:43:58.177361Z",
     "end_time": "2023-04-03T23:43:58.811152Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear Regression From Scratch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class ScratchKNeighborsRegressor:\n",
    "    def __init__(self, n_neighbors=5):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        distances = cdist(X_test, self.X_train)\n",
    "        nearest_indices = np.argsort(distances, axis=1)[:, :self.n_neighbors]\n",
    "        nearest_targets = self.y_train[nearest_indices]\n",
    "        predictions = np.mean(nearest_targets, axis=1)\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T23:44:27.772850Z",
     "end_time": "2023-04-03T23:44:27.789911Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train the model:  2.1457672119140625e-06\n",
      "Mean Squared Error: 0.6476286041930105\n",
      "R-squared Score: -0.24005196319638644\n",
      "-0.029363834499985204\n",
      "-0.01342905790679993\n",
      "Accuracy: 0.7037457434733257\n"
     ]
    }
   ],
   "source": [
    "regressor = ScratchKNeighborsRegressor()\n",
    "\n",
    "# Print the regression coefficients and intercept\n",
    "# print('Coefficients:', regressor.coef_)\n",
    "# print('Intercept:', regressor.intercept_)\n",
    "test_model(regressor, train_x, train_y, test_x, test_y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T23:44:29.022490Z",
     "end_time": "2023-04-03T23:45:01.989430Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class ScratchKNeighborsClassifier:\n",
    "    def __init__(self, n_neighbors=5):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        distances = cdist(X_test, self.X_train)\n",
    "        nearest_indices = np.argsort(distances, axis=1)[:, :self.n_neighbors]\n",
    "        nearest_targets = self.y_train[nearest_indices]\n",
    "        predictions = np.mean(nearest_targets, axis=1)\n",
    "        return predictions>=0.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T00:02:35.689793Z",
     "end_time": "2023-04-04T00:02:35.730681Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train the model:  1.430511474609375e-06\n",
      "Binary cross entropy: 8.068796161644968\n",
      "0.07592382393744482\n",
      "0.20267372934796318\n",
      "Accuracy: 0.7761382267625173\n"
     ]
    }
   ],
   "source": [
    "regressor = ScratchKNeighborsClassifier()\n",
    "test_model(regressor, train_x, train_y, test_x, test_y,classification=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T00:02:54.213575Z",
     "end_time": "2023-04-04T00:03:24.737255Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (58,) (31715,) (58,) ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 32\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mdistances \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m sigma \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m))\n\u001B[1;32m     30\u001B[0m regressor \u001B[38;5;241m=\u001B[39m ScratchLocallyWeightedLinearRegression(num_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, kernel_func\u001B[38;5;241m=\u001B[39mgaussian_kernel, kernel_func_params\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msigma\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m1\u001B[39m})\n\u001B[0;32m---> 32\u001B[0m \u001B[43mtest_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mregressor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_y\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[12], line 3\u001B[0m, in \u001B[0;36mtest_model\u001B[0;34m(model, train_x, train_y, test_x, test_y, classification)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtest_model\u001B[39m(model, train_x, train_y, test_x, test_y,classification\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m      2\u001B[0m     time_start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m----> 3\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_y\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTime taken to train the model: \u001B[39m\u001B[38;5;124m\"\u001B[39m, time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m time_start)\n\u001B[1;32m      5\u001B[0m     pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(test_x)\n",
      "Cell \u001B[0;32mIn[30], line 21\u001B[0m, in \u001B[0;36mScratchLocallyWeightedLinearRegression.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m     16\u001B[0m k\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel_func(x, X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel_func_params)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# self.w += self.lr * error * k\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# self.w+=self.lr *error * np.dot(k,x)\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mw \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(error,k )\n",
      "\u001B[0;31mValueError\u001B[0m: operands could not be broadcast together with shapes (58,) (31715,) (58,) "
     ]
    }
   ],
   "source": [
    "class ScratchLocallyWeightedLinearRegression:\n",
    "    def __init__(self, num_iter, lr, kernel_func, kernel_func_params):\n",
    "        self.num_iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.kernel_func = kernel_func\n",
    "        self.kernel_func_params = kernel_func_params\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.w = np.random.rand(X.shape[1])\n",
    "        for i in range(self.num_iter):\n",
    "            for j in range(X.shape[0]):\n",
    "                x = X[j]\n",
    "                y_pred = self.predict(x)\n",
    "                error = y[j] - y_pred\n",
    "                k=self.kernel_func(x, X, self.kernel_func_params)\n",
    "\n",
    "                # self.w += self.lr * error * k\n",
    "                # self.w+=self.lr *error * np.dot(k,x)\n",
    "\n",
    "                self.w += self.lr * np.dot(error,k )\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.w)\n",
    "def gaussian_kernel(x, X, params):\n",
    "    sigma = params['sigma']\n",
    "    distances = np.linalg.norm(x - X, axis=1)\n",
    "    return np.exp(-distances ** 2 / (2 * sigma ** 2))\n",
    "\n",
    "regressor = ScratchLocallyWeightedLinearRegression(num_iter=100, lr=0.01, kernel_func=gaussian_kernel, kernel_func_params={'sigma': 1})\n",
    "\n",
    "test_model(regressor, train_x, train_y, test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T23:57:14.711652Z",
     "end_time": "2023-04-03T23:57:23.152157Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
